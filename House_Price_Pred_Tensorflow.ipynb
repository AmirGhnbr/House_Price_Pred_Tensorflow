{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMM9O21JN4oRgdnRvzJs224",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirGhnbr/House_Price_Pred_Tensorflow/blob/dev_branch/House_Price_Pred_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kBa77Bhsqui5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets take a look at tensorflow version\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkdObpaorR7N",
        "outputId": "a5c17c91-dd5c-44e8-e5b0-5aed4e16470a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import our data\n",
        "initial_data_train = pd.read_csv(\"https://raw.githubusercontent.com/AmirGhnbr/house-price-prediction/main/train.csv\")\n",
        "initial_data_test = pd.read_csv(\"https://raw.githubusercontent.com/AmirGhnbr/house-price-prediction/main/test.csv\")\n",
        "initial_data_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "C41-VGh7roRY",
        "outputId": "11fc857b-6e19-41cf-d950-4ffd988745b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2ba3e61-5870-4a9c-8167-28c3a9f80da0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2ba3e61-5870-4a9c-8167-28c3a9f80da0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2ba3e61-5870-4a9c-8167-28c3a9f80da0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2ba3e61-5870-4a9c-8167-28c3a9f80da0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_data_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzz3e-25sUGK",
        "outputId": "3cfe8f07-3e3c-43c5-9ba7-db2b717ad5a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_data_train.isna().sum().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smoke8c4tLMe",
        "outputId": "fdeca872-a6c8-40ec-853f-05819a0e5a65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                0\n",
              "MSSubClass        0\n",
              "MSZoning          0\n",
              "LotFrontage     259\n",
              "LotArea           0\n",
              "Street            0\n",
              "Alley          1369\n",
              "LotShape          0\n",
              "LandContour       0\n",
              "Utilities         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_data_train.dtypes.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fn4dsgHtRKP",
        "outputId": "9d78b5fd-b305-4c06-cab4-f139c66523ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               int64\n",
              "MSSubClass       int64\n",
              "MSZoning        object\n",
              "LotFrontage    float64\n",
              "LotArea          int64\n",
              "Street          object\n",
              "Alley           object\n",
              "LotShape        object\n",
              "LandContour     object\n",
              "Utilities       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_data_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "z3optTfdtUCL",
        "outputId": "23dcd9a9-ff90-450c-ddfc-fcced252eaca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
              "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
              "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
              "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
              "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
              "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
              "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
              "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
              "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
              "\n",
              "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
              "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
              "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
              "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
              "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
              "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
              "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
              "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
              "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-101236ee-4a03-411b-9c35-4cbdb8d93821\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-101236ee-4a03-411b-9c35-4cbdb8d93821')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-101236ee-4a03-411b-9c35-4cbdb8d93821 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-101236ee-4a03-411b-9c35-4cbdb8d93821');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We have numeric and categoric data so we need to convert categoric data into numeric\n",
        "\n",
        "### using pandas get_dummies function"
      ],
      "metadata": {
        "id": "zwlR31M5txCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode the data\n",
        "train_one_hot = pd.get_dummies(initial_data_train)\n",
        "train_one_hot.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "5zfbZCAEtzAs",
        "outputId": "83efb95e-a4ea-4101-9196-fec37702075d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0   1          60         65.0     8450            7            5       2003   \n",
              "1   2          20         80.0     9600            6            8       1976   \n",
              "2   3          60         68.0    11250            7            5       2001   \n",
              "3   4          70         60.0     9550            7            5       1915   \n",
              "4   5          60         84.0    14260            8            5       2000   \n",
              "\n",
              "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  SaleType_New  \\\n",
              "0          2003       196.0         706  ...               0             0   \n",
              "1          1976         0.0         978  ...               0             0   \n",
              "2          2002       162.0         486  ...               0             0   \n",
              "3          1970         0.0         216  ...               0             0   \n",
              "4          2000       350.0         655  ...               0             0   \n",
              "\n",
              "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
              "0             0            1                      0                      0   \n",
              "1             0            1                      0                      0   \n",
              "2             0            1                      0                      0   \n",
              "3             0            1                      1                      0   \n",
              "4             0            1                      0                      0   \n",
              "\n",
              "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
              "0                     0                     0                     1   \n",
              "1                     0                     0                     1   \n",
              "2                     0                     0                     1   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     1   \n",
              "\n",
              "   SaleCondition_Partial  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 290 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89b6d51f-e4a6-4f34-b11d-c2b5140fabea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 290 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89b6d51f-e4a6-4f34-b11d-c2b5140fabea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89b6d51f-e4a6-4f34-b11d-c2b5140fabea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89b6d51f-e4a6-4f34-b11d-c2b5140fabea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_one_hot.drop([\"SalePrice\"],axis=1)\n",
        "y = train_one_hot[\"SalePrice\"]\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "mbXrO_Y7uZED",
        "outputId": "01387bbc-6dd4-4586-d332-1b942697f9fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0   1          60         65.0     8450            7            5       2003   \n",
              "1   2          20         80.0     9600            6            8       1976   \n",
              "2   3          60         68.0    11250            7            5       2001   \n",
              "3   4          70         60.0     9550            7            5       1915   \n",
              "4   5          60         84.0    14260            8            5       2000   \n",
              "\n",
              "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  SaleType_New  \\\n",
              "0          2003       196.0         706  ...               0             0   \n",
              "1          1976         0.0         978  ...               0             0   \n",
              "2          2002       162.0         486  ...               0             0   \n",
              "3          1970         0.0         216  ...               0             0   \n",
              "4          2000       350.0         655  ...               0             0   \n",
              "\n",
              "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
              "0             0            1                      0                      0   \n",
              "1             0            1                      0                      0   \n",
              "2             0            1                      0                      0   \n",
              "3             0            1                      1                      0   \n",
              "4             0            1                      0                      0   \n",
              "\n",
              "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
              "0                     0                     0                     1   \n",
              "1                     0                     0                     1   \n",
              "2                     0                     0                     1   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     1   \n",
              "\n",
              "   SaleCondition_Partial  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      0  \n",
              "\n",
              "[5 rows x 289 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-571ab363-66df-4b6a-8784-0c0bc3618dd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 289 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-571ab363-66df-4b6a-8784-0c0bc3618dd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-571ab363-66df-4b6a-8784-0c0bc3618dd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-571ab363-66df-4b6a-8784-0c0bc3618dd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRCfXNt5vLSR",
        "outputId": "04ae123e-a4b7-4ccf-b14c-eee4806cbf01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    208500\n",
              "1    181500\n",
              "2    223500\n",
              "3    140000\n",
              "4    250000\n",
              "Name: SalePrice, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the data"
      ],
      "metadata": {
        "id": "NcJnbwycvkEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "X_train= X_train.dropna(axis=1)\n",
        "X_test = X_test.dropna(axis=1)\n",
        "y_train.isna().sum()"
      ],
      "metadata": {
        "id": "9BuHT8Y63xoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2207af-2ff0-468d-b8ad-7794932e8480"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the first model and then improve it"
      ],
      "metadata": {
        "id": "wYyvao1A4W3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# create the basic structure of model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model which means specifying how model works\n",
        "model_1.compile(loss= tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# fitting the model into the train data\n",
        "model_1.fit(X_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "IWluPd_T4ef-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3b6e33-be89-4def-df8e-59751072d242"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 124992.9844 - mae: 124992.9844\n",
            "Epoch 2/20\n",
            "37/37 [==============================] - 0s 914us/step - loss: 156550.3281 - mae: 156550.3281\n",
            "Epoch 3/20\n",
            "37/37 [==============================] - 0s 932us/step - loss: 137251.3281 - mae: 137251.3281\n",
            "Epoch 4/20\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 133897.5781 - mae: 133897.5781\n",
            "Epoch 5/20\n",
            "37/37 [==============================] - 0s 845us/step - loss: 131890.8281 - mae: 131890.8281\n",
            "Epoch 6/20\n",
            "37/37 [==============================] - 0s 821us/step - loss: 125211.1094 - mae: 125211.1094\n",
            "Epoch 7/20\n",
            "37/37 [==============================] - 0s 857us/step - loss: 126995.3047 - mae: 126995.3047\n",
            "Epoch 8/20\n",
            "37/37 [==============================] - 0s 829us/step - loss: 143999.6250 - mae: 143999.6250\n",
            "Epoch 9/20\n",
            "37/37 [==============================] - 0s 859us/step - loss: 137290.3750 - mae: 137290.3750\n",
            "Epoch 10/20\n",
            "37/37 [==============================] - 0s 912us/step - loss: 135568.8906 - mae: 135568.8906\n",
            "Epoch 11/20\n",
            "37/37 [==============================] - 0s 896us/step - loss: 143230.9688 - mae: 143230.9688\n",
            "Epoch 12/20\n",
            "37/37 [==============================] - 0s 962us/step - loss: 149668.3438 - mae: 149668.3438\n",
            "Epoch 13/20\n",
            "37/37 [==============================] - 0s 945us/step - loss: 136589.9531 - mae: 136589.9531\n",
            "Epoch 14/20\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 123790.3828 - mae: 123790.3828\n",
            "Epoch 15/20\n",
            "37/37 [==============================] - 0s 861us/step - loss: 140918.7969 - mae: 140918.7969\n",
            "Epoch 16/20\n",
            "37/37 [==============================] - 0s 996us/step - loss: 141434.3906 - mae: 141434.3906\n",
            "Epoch 17/20\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 147295.7969 - mae: 147295.7969\n",
            "Epoch 18/20\n",
            "37/37 [==============================] - 0s 834us/step - loss: 140874.6250 - mae: 140874.6250\n",
            "Epoch 19/20\n",
            "37/37 [==============================] - 0s 838us/step - loss: 147081.6094 - mae: 147081.6094\n",
            "Epoch 20/20\n",
            "37/37 [==============================] - 0s 895us/step - loss: 141953.3281 - mae: 141953.3281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff73577da10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd5tRbVSDM4",
        "outputId": "593e0764-115d-49b1-88a1-69d3200c5913"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 133263.9219 - mae: 133263.9219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[133263.921875, 133263.921875]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred = model_1.predict(X_test)\n",
        "model_1_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo4lThTkAB74",
        "outputId": "c4b0ec8a-cef5-4e55-9157-e80c53421699"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40311.508  ],\n",
              "       [54570.81   ],\n",
              "       [45243.293  ],\n",
              "       [15206.907  ],\n",
              "       [63334.14   ],\n",
              "       [  301.45416],\n",
              "       [83588.84   ],\n",
              "       [ -513.2901 ],\n",
              "       [ 3366.12   ],\n",
              "       [93107.13   ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To imporve the model performance we can take these steps:\n",
        "\n",
        "1. scale the inpute data\n",
        "2. make the network deeper\n",
        "3. change the hidden units\n",
        "4. change the activation function\n",
        "5. regularizatin & dropout & early stopping for fighting againts overfitting\n",
        "5. use better optimizer\n",
        "6. use better loss function\n",
        "7. use mini_batch\n",
        "8. train for loger(increase the number of epochs)"
      ],
      "metadata": {
        "id": "5eu0m1hJWGRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_performance(model_history):\n",
        "  pd.DataFrame(model_history.history).plot()\n",
        "  plt.grid(True)\n",
        "  plt.xlabel(\"loss\")\n",
        "  plt.ylabel(\"epoch\")"
      ],
      "metadata": {
        "id": "PQ6JFRDEWXfl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the dataset using sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "j8EaR7JmYUkQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## model_2\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "## compile the model\n",
        "model_2.compile(loss = tf.keras.losses.huber,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = \"mae\")\n",
        "\n",
        "## fit the model to train data\n",
        "history = model_2.fit(X_train, y_train, epochs=200)"
      ],
      "metadata": {
        "id": "jBnVPnpyaDTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644b8574-8e4c-4aea-d5fc-affce2b02b9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 1s 3ms/step - loss: 181433.8594 - mae: 181434.3594\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 181390.7344 - mae: 181391.2344\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 181217.1719 - mae: 181217.6562\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 180729.0625 - mae: 180729.5312\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 179689.3594 - mae: 179689.8438\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 177857.6875 - mae: 177858.1875\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 174972.7656 - mae: 174973.2500\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 170829.5469 - mae: 170830.0469\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 165167.5156 - mae: 165168.0312\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 157861.5156 - mae: 157862.0156\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 148953.2812 - mae: 148953.7812\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 138349.1094 - mae: 138349.6094\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 126801.8594 - mae: 126802.3594\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 114723.4922 - mae: 114723.9922\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 102292.5859 - mae: 102293.0859\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 89952.2812 - mae: 89952.7812\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 77433.8594 - mae: 77434.3594\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 65510.8164 - mae: 65511.3164\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 56263.2891 - mae: 56263.7891\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 50465.7969 - mae: 50466.2969\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 46865.3086 - mae: 46865.8086\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 44125.5234 - mae: 44126.0234\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 41778.1172 - mae: 41778.6172\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 39965.8125 - mae: 39966.3125\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 38418.2578 - mae: 38418.7578\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 37026.5898 - mae: 37027.0898\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 35833.7656 - mae: 35834.2656\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 34754.2109 - mae: 34754.7109\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 33770.0977 - mae: 33770.5977\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 32901.3555 - mae: 32901.8555\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 32099.7910 - mae: 32100.2910\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 31371.2910 - mae: 31371.7910\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 30718.6133 - mae: 30719.1133\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 30091.1055 - mae: 30091.6055\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 29532.0859 - mae: 29532.5859\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 29020.3867 - mae: 29020.8867\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 28531.1367 - mae: 28531.6367\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 28062.1875 - mae: 28062.6875\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 27603.5039 - mae: 27604.0039\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 27188.6309 - mae: 27189.1309\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 26797.0605 - mae: 26797.5605\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 26432.4824 - mae: 26432.9824\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 26052.6367 - mae: 26053.1367\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 25719.9785 - mae: 25720.4785\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 25376.2852 - mae: 25376.7852\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 25071.9277 - mae: 25072.4277\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 24757.0625 - mae: 24757.5625\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 24545.9590 - mae: 24546.4590\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 24172.4219 - mae: 24172.9219\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23932.5566 - mae: 23933.0566\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23624.5098 - mae: 23625.0098\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23384.9785 - mae: 23385.4785\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23138.9375 - mae: 23139.4375\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 22894.0918 - mae: 22894.5918\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 22648.5352 - mae: 22649.0352\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 22438.9297 - mae: 22439.4297\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 22195.6680 - mae: 22196.1680\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 21994.9922 - mae: 21995.4922\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 21781.9199 - mae: 21782.4199\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 21576.9434 - mae: 21577.4434\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 21348.3340 - mae: 21348.8340\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 21164.3730 - mae: 21164.8730\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 20951.6875 - mae: 20952.1875\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 20754.6484 - mae: 20755.1484\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 20551.9219 - mae: 20552.4219\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 20375.2324 - mae: 20375.7324\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 20170.8438 - mae: 20171.3438\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19998.6172 - mae: 19999.1172\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 19790.6406 - mae: 19791.1406\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19640.7461 - mae: 19641.2461\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19471.6406 - mae: 19472.1406\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19326.3965 - mae: 19326.8965\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19151.8086 - mae: 19152.3086\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 19015.6465 - mae: 19016.1465\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 18850.2852 - mae: 18850.7852\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 18698.2344 - mae: 18698.7344\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 18569.4590 - mae: 18569.9590\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 18418.5215 - mae: 18419.0215\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 18280.3281 - mae: 18280.8281\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 18129.5312 - mae: 18130.0312\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17973.7910 - mae: 17974.2910\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17855.1172 - mae: 17855.6172\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17734.5664 - mae: 17735.0664\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17605.2578 - mae: 17605.7578\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17491.9570 - mae: 17492.4570\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17365.5254 - mae: 17366.0254\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17235.3613 - mae: 17235.8613\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17125.3164 - mae: 17125.8164\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 17013.5762 - mae: 17014.0762\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16920.4473 - mae: 16920.9473\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16768.1328 - mae: 16768.6328\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16690.5117 - mae: 16691.0117\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16553.5957 - mae: 16554.0957\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16438.9141 - mae: 16439.4141\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16345.1592 - mae: 16345.6592\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16240.0020 - mae: 16240.5020\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16130.3750 - mae: 16130.8750\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 16057.3711 - mae: 16057.8711\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15938.5752 - mae: 15939.0752\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15858.1250 - mae: 15858.6250\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15731.3643 - mae: 15731.8643\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15686.7793 - mae: 15687.2793\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15576.5449 - mae: 15577.0449\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15482.2119 - mae: 15482.7119\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15379.0312 - mae: 15379.5312\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15320.6709 - mae: 15321.1709\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15211.8906 - mae: 15212.3906\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15134.5869 - mae: 15135.0869\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 15041.3633 - mae: 15041.8633\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14951.0322 - mae: 14951.5322\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 14860.5225 - mae: 14861.0225\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14788.3271 - mae: 14788.8271\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14704.9707 - mae: 14705.4707\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14621.7158 - mae: 14622.2158\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14612.6982 - mae: 14613.1982\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14482.7998 - mae: 14483.2998\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14411.8994 - mae: 14412.3975\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14355.7197 - mae: 14356.2197\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14275.4883 - mae: 14275.9883\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14232.9570 - mae: 14233.4561\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14144.3828 - mae: 14144.8828\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 14066.4336 - mae: 14066.9336\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 14016.2119 - mae: 14016.7119\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13940.5088 - mae: 13941.0088\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13854.5400 - mae: 13855.0400\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13799.9658 - mae: 13800.4658\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13745.4492 - mae: 13745.9492\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13677.4834 - mae: 13677.9834\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13631.6699 - mae: 13632.1699\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 13564.6445 - mae: 13565.1445\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13519.1123 - mae: 13519.6123\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 13456.4785 - mae: 13456.9785\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13403.8779 - mae: 13404.3779\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13356.8994 - mae: 13357.3994\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13282.6201 - mae: 13283.1201\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13230.8799 - mae: 13231.3799\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13201.6572 - mae: 13202.1572\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13122.8398 - mae: 13123.3398\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 13077.7500 - mae: 13078.2500\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 13030.3779 - mae: 13030.8779\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12972.5586 - mae: 12973.0586\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12905.1289 - mae: 12905.6289\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12850.8008 - mae: 12851.3008\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12789.9492 - mae: 12790.4492\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12751.4072 - mae: 12751.9062\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12695.2393 - mae: 12695.7393\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12652.7285 - mae: 12653.2285\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12590.5566 - mae: 12591.0566\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 12546.8213 - mae: 12547.3213\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12521.8369 - mae: 12522.3369\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12457.4521 - mae: 12457.9512\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12447.9990 - mae: 12448.4990\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12370.2637 - mae: 12370.7637\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12332.0625 - mae: 12332.5625\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 12288.5254 - mae: 12289.0254\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12236.5049 - mae: 12237.0049\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12192.4443 - mae: 12192.9443\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12144.3594 - mae: 12144.8594\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12131.4951 - mae: 12131.9951\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12062.6436 - mae: 12063.1436\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 12018.5957 - mae: 12019.0957\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11982.7842 - mae: 11983.2842\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11947.4365 - mae: 11947.9365\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11888.0557 - mae: 11888.5557\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11894.9209 - mae: 11895.4209\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 11812.4600 - mae: 11812.9600\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11776.7979 - mae: 11777.2979\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11716.0010 - mae: 11716.5010\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11707.0703 - mae: 11707.5703\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11667.7393 - mae: 11668.2393\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11618.7451 - mae: 11619.2441\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11570.9395 - mae: 11571.4395\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11542.4443 - mae: 11542.9443\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11516.7949 - mae: 11517.2949\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11489.0244 - mae: 11489.5244\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11417.6494 - mae: 11418.1494\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11408.5840 - mae: 11409.0840\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11353.1973 - mae: 11353.6973\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 11327.7822 - mae: 11328.2822\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11279.9121 - mae: 11280.4121\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11223.8887 - mae: 11224.3887\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11186.4609 - mae: 11186.9609\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 11165.3193 - mae: 11165.8184\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11122.3242 - mae: 11122.8242\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11084.5723 - mae: 11085.0723\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11068.1504 - mae: 11068.6504\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 11030.9697 - mae: 11031.4697\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 11007.9414 - mae: 11008.4414\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10964.9238 - mae: 10965.4238\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10944.6006 - mae: 10945.1006\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10887.8857 - mae: 10888.3857\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10880.5752 - mae: 10881.0752\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10828.9932 - mae: 10829.4932\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 10811.7002 - mae: 10812.2002\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10798.4053 - mae: 10798.9053\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10756.2168 - mae: 10756.7168\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10713.3828 - mae: 10713.8828\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10681.4346 - mae: 10681.9346\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10657.3447 - mae: 10657.8447\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 10616.4287 - mae: 10616.9287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(X_test , y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQrbSYZ5cziz",
        "outputId": "97e83fab-c422-4e78-9c74-b09444e4a550"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 21195.1934 - mae: 21195.6934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21195.193359375, 21195.693359375]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_performance(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "SHrMm38G8AiJ",
        "outputId": "ce81247b-8452-4c4c-f8ba-30c5c7c56e7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As we expected the model is overfitting the training data so we need to use regularizatin & dropout & early stopping"
      ],
      "metadata": {
        "id": "wYvtg7VfdXLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build model 3 with regularization & dropout & early stopping\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_regularizer=tf.keras.regularizers.L1(0.3),\n",
        "                          activity_regularizer=tf.keras.regularizers.L2(0.3)),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_regularizer=tf.keras.regularizers.L1(0.3),\n",
        "                          activity_regularizer=tf.keras.regularizers.L2(0.3)),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_3.compile(loss = tf.keras.losses.huber,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = \"mae\")\n",
        "\n",
        "# early stopping callback\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                     restore_best_weights=True)\n",
        "\n",
        "# fit the model\n",
        "model_3_history = model_3.fit(X_train, y_train, epochs=200,\n",
        "                              validation_data=(X_test, y_test),\n",
        "                              callbacks=[early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZRbCc2wFMEC",
        "outputId": "75b53bdc-84e5-4f2a-f18c-4c93de03c597"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 1s 6ms/step - loss: 182082.2812 - mae: 181438.3594 - val_loss: 179297.6250 - val_mae: 178834.7188\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 181768.6250 - mae: 181434.5469 - val_loss: 179044.7188 - val_mae: 178831.0625\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 181565.9062 - mae: 181428.4688 - val_loss: 178892.7656 - val_mae: 178819.5781\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 181449.8125 - mae: 181404.7031 - val_loss: 178799.0938 - val_mae: 178769.7031\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 181183.6562 - mae: 181107.1719 - val_loss: 177902.2812 - val_mae: 177643.5312\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 178071.5156 - mae: 176484.2812 - val_loss: 171131.6094 - val_mae: 166273.4219\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 167387.3594 - mae: 155761.5156 - val_loss: 156428.8125 - val_mae: 136705.0312\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 149055.2812 - mae: 120615.9141 - val_loss: 134618.1406 - val_mae: 97707.5078\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 124470.1406 - mae: 78858.4297 - val_loss: 110391.6406 - val_mae: 60341.0430\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 101379.4062 - mae: 51019.1445 - val_loss: 92576.0312 - val_mae: 45356.6406\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 85213.0469 - mae: 39729.9688 - val_loss: 80109.4375 - val_mae: 38753.5977\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 73911.8359 - mae: 33203.6328 - val_loss: 71397.5938 - val_mae: 35021.3320\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 66122.6328 - mae: 28395.8633 - val_loss: 64579.0469 - val_mae: 30878.3184\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 59630.7109 - mae: 25340.4453 - val_loss: 59817.9922 - val_mae: 28663.5547\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 55151.7422 - mae: 24302.7402 - val_loss: 56075.4258 - val_mae: 27309.6797\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 51871.9883 - mae: 23097.0215 - val_loss: 53261.5508 - val_mae: 26781.4609\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 48845.1328 - mae: 22324.5879 - val_loss: 50271.5156 - val_mae: 25596.7285\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 45866.6992 - mae: 21088.2715 - val_loss: 47426.0625 - val_mae: 24461.7695\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 44513.5703 - mae: 21255.8027 - val_loss: 45363.4688 - val_mae: 24129.6777\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 41249.1172 - mae: 19246.5879 - val_loss: 44255.4414 - val_mae: 24120.2031\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 39904.0859 - mae: 19550.0176 - val_loss: 42173.1250 - val_mae: 22930.0410\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 38298.3711 - mae: 18543.9453 - val_loss: 41122.1758 - val_mae: 22977.0273\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 37918.5117 - mae: 19293.6055 - val_loss: 39603.3203 - val_mae: 22245.8398\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 35543.3320 - mae: 17776.2305 - val_loss: 38868.7539 - val_mae: 21519.5879\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 34803.2891 - mae: 17609.3574 - val_loss: 37535.2812 - val_mae: 21473.1445\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 33912.5625 - mae: 17566.1035 - val_loss: 36699.4258 - val_mae: 21106.6816\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 32929.6094 - mae: 17192.3047 - val_loss: 35347.9023 - val_mae: 20814.2227\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 32111.3906 - mae: 17249.6172 - val_loss: 34886.8320 - val_mae: 20124.7715\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 31717.6953 - mae: 16936.9043 - val_loss: 34502.4805 - val_mae: 20521.2578\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 30440.1582 - mae: 16414.2715 - val_loss: 33500.7930 - val_mae: 20003.3906\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 30368.4219 - mae: 16904.4648 - val_loss: 32687.9355 - val_mae: 19791.8848\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 29611.3496 - mae: 16581.1094 - val_loss: 32583.5273 - val_mae: 19951.7988\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 28204.4785 - mae: 15406.4541 - val_loss: 32568.6172 - val_mae: 20639.0352\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 27911.6270 - mae: 15623.1699 - val_loss: 31332.4590 - val_mae: 19775.3750\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 27748.9199 - mae: 15902.0635 - val_loss: 31391.3906 - val_mae: 20165.8965\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 27362.2852 - mae: 15654.5342 - val_loss: 30462.0918 - val_mae: 19357.8066\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 26519.4980 - mae: 15266.0859 - val_loss: 30615.6230 - val_mae: 19747.6680\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 26376.4375 - mae: 15430.6289 - val_loss: 29657.1094 - val_mae: 19075.7578\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 25435.1387 - mae: 14837.1592 - val_loss: 29279.2676 - val_mae: 18968.5254\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 25702.3535 - mae: 15341.1162 - val_loss: 29068.3555 - val_mae: 19297.5840\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 25145.9434 - mae: 15010.0293 - val_loss: 29095.0625 - val_mae: 19665.4414\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 24640.3438 - mae: 14897.5293 - val_loss: 28308.5312 - val_mae: 18910.5156\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 23910.2012 - mae: 14290.7852 - val_loss: 28381.1387 - val_mae: 19112.9766\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 24217.0820 - mae: 14875.4434 - val_loss: 28251.6562 - val_mae: 19531.4395\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 24289.2949 - mae: 15250.3047 - val_loss: 27490.7871 - val_mae: 18752.5000\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23132.2852 - mae: 14222.8135 - val_loss: 27150.0527 - val_mae: 18623.5215\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 23266.7891 - mae: 14502.6699 - val_loss: 27203.7676 - val_mae: 18815.0703\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 22385.6875 - mae: 13747.9844 - val_loss: 26728.8125 - val_mae: 18542.0957\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 22649.6289 - mae: 14302.3184 - val_loss: 26949.7988 - val_mae: 19113.3359\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 21499.9863 - mae: 13275.9668 - val_loss: 26438.8125 - val_mae: 18580.3574\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 21869.8320 - mae: 13819.2256 - val_loss: 26510.0059 - val_mae: 18732.4316\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 21428.8613 - mae: 13570.8496 - val_loss: 26537.7598 - val_mae: 19102.6074\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 21701.4395 - mae: 14010.5107 - val_loss: 26437.5879 - val_mae: 18832.3516\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 21562.4941 - mae: 13874.2432 - val_loss: 26564.3301 - val_mae: 19088.9746\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 21037.2109 - mae: 13534.5645 - val_loss: 26225.1777 - val_mae: 18994.7871\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 20506.0000 - mae: 13204.9316 - val_loss: 25821.5488 - val_mae: 18653.5488\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 21013.2012 - mae: 13786.3193 - val_loss: 26000.9629 - val_mae: 19012.0879\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 20441.0273 - mae: 13323.6416 - val_loss: 25079.6406 - val_mae: 18246.3984\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 20461.0742 - mae: 13520.8408 - val_loss: 25003.8672 - val_mae: 18269.5879\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 19936.9160 - mae: 13044.3555 - val_loss: 24873.0859 - val_mae: 18315.6328\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 20683.3242 - mae: 14010.1768 - val_loss: 25005.5918 - val_mae: 18513.9473\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 20013.1934 - mae: 13338.4277 - val_loss: 24420.8965 - val_mae: 18060.9414\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 20139.7109 - mae: 13617.9463 - val_loss: 24362.3008 - val_mae: 18091.7422\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 20030.5547 - mae: 13681.6221 - val_loss: 24277.8398 - val_mae: 18111.5879\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 19924.2598 - mae: 13542.5820 - val_loss: 24096.6660 - val_mae: 18055.4805\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 19993.7188 - mae: 13838.1465 - val_loss: 24796.4609 - val_mae: 19028.3418\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 19622.3105 - mae: 13542.9199 - val_loss: 23768.2969 - val_mae: 17804.4883\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 19342.1953 - mae: 13315.2256 - val_loss: 23716.9258 - val_mae: 17866.7578\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 18931.2559 - mae: 12973.4688 - val_loss: 23957.1172 - val_mae: 18219.3203\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 18881.1699 - mae: 13035.5371 - val_loss: 24052.1875 - val_mae: 18484.4609\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18789.3574 - mae: 13041.3896 - val_loss: 24151.2988 - val_mae: 18487.6348\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 19142.9512 - mae: 13409.7168 - val_loss: 24163.1543 - val_mae: 18513.1992\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18293.1914 - mae: 12625.8730 - val_loss: 24049.1719 - val_mae: 18674.4102\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 18887.4746 - mae: 13378.1895 - val_loss: 24316.1562 - val_mae: 19079.8691\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 18945.7988 - mae: 13541.6357 - val_loss: 23628.2871 - val_mae: 18357.2969\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 18679.3301 - mae: 13289.7793 - val_loss: 23410.7852 - val_mae: 18174.5098\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18390.1699 - mae: 13059.2598 - val_loss: 23615.3281 - val_mae: 18546.2910\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18457.0371 - mae: 13233.0723 - val_loss: 23300.1055 - val_mae: 18289.9297\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18146.1426 - mae: 13010.3477 - val_loss: 23738.4219 - val_mae: 18622.5625\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 17803.8320 - mae: 12648.1846 - val_loss: 23317.0742 - val_mae: 18322.3770\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 18036.5430 - mae: 13004.3477 - val_loss: 22951.7734 - val_mae: 17958.7188\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 18008.0000 - mae: 13008.0312 - val_loss: 23583.6953 - val_mae: 18852.3770\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 17195.1328 - mae: 12262.8633 - val_loss: 22841.6816 - val_mae: 17992.1816\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 17781.2832 - mae: 12919.7764 - val_loss: 22965.6934 - val_mae: 18220.5586\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 17793.0859 - mae: 12990.0020 - val_loss: 23263.1465 - val_mae: 18622.9863\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 17822.0352 - mae: 13059.0059 - val_loss: 22426.1504 - val_mae: 17765.2188\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 17381.1328 - mae: 12701.1377 - val_loss: 23199.7539 - val_mae: 18556.6992\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 17083.5195 - mae: 12438.7002 - val_loss: 22746.9258 - val_mae: 18155.2578\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 16737.5938 - mae: 12121.2139 - val_loss: 22774.8828 - val_mae: 18298.9727\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 17697.1914 - mae: 13172.5186 - val_loss: 22996.0449 - val_mae: 18674.9824\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16845.7676 - mae: 12330.6914 - val_loss: 22672.2676 - val_mae: 18214.5840\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16993.8066 - mae: 12530.8125 - val_loss: 22534.0625 - val_mae: 18256.6348\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16505.6074 - mae: 12079.5107 - val_loss: 22218.0918 - val_mae: 17828.5156\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16556.7012 - mae: 12187.4453 - val_loss: 22304.8418 - val_mae: 17941.7676\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16530.8027 - mae: 12191.5566 - val_loss: 22328.7422 - val_mae: 18096.8672\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16583.6445 - mae: 12273.9736 - val_loss: 22788.7676 - val_mae: 18516.7109\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16388.0254 - mae: 12114.0986 - val_loss: 22247.0137 - val_mae: 18180.4297\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16529.6152 - mae: 12364.5000 - val_loss: 22225.7578 - val_mae: 18142.7012\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16484.2539 - mae: 12357.8711 - val_loss: 22060.7285 - val_mae: 17906.0098\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16139.9336 - mae: 12016.6768 - val_loss: 22427.3438 - val_mae: 18492.2305\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16189.5752 - mae: 12156.9873 - val_loss: 22178.4199 - val_mae: 18223.5098\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 16128.2041 - mae: 12123.5010 - val_loss: 21876.3086 - val_mae: 17934.0215\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16363.0117 - mae: 12360.3086 - val_loss: 22022.4648 - val_mae: 18070.8770\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15794.9414 - mae: 11841.8740 - val_loss: 22096.9961 - val_mae: 18235.0488\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15819.3086 - mae: 11939.8096 - val_loss: 21840.7285 - val_mae: 18112.4043\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 16149.5137 - mae: 12267.7764 - val_loss: 21625.2148 - val_mae: 17884.0488\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15896.3457 - mae: 12089.7686 - val_loss: 22032.9473 - val_mae: 18396.8262\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15727.4980 - mae: 11942.7939 - val_loss: 21208.7070 - val_mae: 17484.9863\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15546.1914 - mae: 11758.4014 - val_loss: 21736.8555 - val_mae: 18019.1445\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15764.7363 - mae: 12026.3447 - val_loss: 21840.3438 - val_mae: 18264.2930\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15470.0586 - mae: 11801.1172 - val_loss: 21906.7363 - val_mae: 18314.9961\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15959.6777 - mae: 12297.8701 - val_loss: 21705.3379 - val_mae: 18185.8203\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15900.7979 - mae: 12295.0518 - val_loss: 21387.2598 - val_mae: 17857.1797\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15141.2979 - mae: 11514.9736 - val_loss: 21394.4102 - val_mae: 17859.1680\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15462.4404 - mae: 11890.7695 - val_loss: 21522.7090 - val_mae: 17974.9746\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 15219.2188 - mae: 11657.4434 - val_loss: 21881.9258 - val_mae: 18382.4336\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15797.9980 - mae: 12272.6289 - val_loss: 21608.9004 - val_mae: 18208.3750\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 15503.0205 - mae: 12018.0215 - val_loss: 21512.3730 - val_mae: 18196.9668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(X_test , y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mJ552kgIEPO",
        "outputId": "f4a11e37-f638-4b16-d134-cd24fb4a34dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 21208.7070 - mae: 17484.9863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21208.70703125, 17484.986328125]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmJ5BAomJDpt"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}